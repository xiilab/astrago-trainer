# Kubeflow Training Operator v2 - Backend ê°œë°œ ê°€ì´ë“œ

ë°±ì—”ë“œ ê°œë°œìë¥¼ ìœ„í•œ TrainJob ìƒì„± ê°€ì´ë“œì…ë‹ˆë‹¤.
**UIì—ì„œ ë°›ì€ ê°’ë“¤ì„ TrainJob YAMLì˜ ì–´ë””ì— ë„£ì–´ì•¼ í•˜ëŠ”ì§€** ëª…í™•í•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## ğŸ“‹ ëª©ì°¨
- [UI ì…ë ¥ â†’ TrainJob ë§¤í•‘](#ui-ì…ë ¥--trainjob-ë§¤í•‘)
- [Backend êµ¬í˜„ ê°€ì´ë“œ](#backend-êµ¬í˜„-ê°€ì´ë“œ)
- [í”„ë ˆì„ì›Œí¬ë³„ ì°¨ì´ì ](#í”„ë ˆì„ì›Œí¬ë³„-ì°¨ì´ì )
- [ë°°í¬ ë° í…ŒìŠ¤íŠ¸](#ë°°í¬-ë°-í…ŒìŠ¤íŠ¸)

---

## UI ì…ë ¥ â†’ TrainJob ë§¤í•‘

ì‚¬ìš©ìê°€ UIì—ì„œ ì…ë ¥í•˜ëŠ” ê°’ë“¤ê³¼ TrainJob YAML í•„ë“œì˜ ë§¤í•‘ ê´€ê³„ì…ë‹ˆë‹¤.

### ğŸ“¥ UI ì…ë ¥ í•­ëª©

| UI í•­ëª© | ì„¤ëª… | ì˜ˆì‹œ ê°’ |
|---------|------|---------|
| **ì´ë¯¸ì§€ ì£¼ì†Œ** | í•™ìŠµì— ì‚¬ìš©í•  Docker ì´ë¯¸ì§€ | `pytorch/pytorch:2.2.2-cuda11.8-cudnn8-runtime` |
| **CPU** | ì»¨í…Œì´ë„ˆë‹¹ CPU ìš”ì²­/ì œí•œ | `2` / `4` |
| **MEMORY** | ì»¨í…Œì´ë„ˆë‹¹ ë©”ëª¨ë¦¬ ìš”ì²­/ì œí•œ | `8Gi` / `16Gi` |
| **GPU** | ì»¨í…Œì´ë„ˆë‹¹ GPU ê°œìˆ˜ | `1` |
| **ë¶„ì‚°í•™ìŠµ ë…¸ë“œ ê°œìˆ˜** | í•™ìŠµì— ì‚¬ìš©í•  ë…¸ë“œ(ì›Œì»¤) ìˆ˜ | `2` |
| **ë³¼ë¥¨ ë§ˆìš´íŠ¸** | ì†ŒìŠ¤ì½”ë“œ, ë°ì´í„°ì…‹, ëª¨ë¸ ì €ì¥ì†Œ | `[{"name": "code", "path": "/workspace"}, ...]` |
| **ì»¤ë§¨ë“œ** | ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ëª…ë ¹ | `python /workspace/scripts/train.py` |
| **í™˜ê²½ë³€ìˆ˜** | ì‚¬ìš©ì ì •ì˜ í™˜ê²½ë³€ìˆ˜ | `[{"name": "EPOCHS", "value": "10"}, ...]` |

---

### ğŸ¯ TrainJob YAML ë§¤í•‘

#### **PyTorch TrainJob ì˜ˆì‹œ**

```yaml
apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainJob
metadata:
  name: user-job-12345                    # Backendê°€ ìƒì„± (user_id + timestamp)
  namespace: user-namespace               # ì‚¬ìš©ì ë„¤ì„ìŠ¤í˜ì´ìŠ¤
spec:
  runtimeRef:
    name: pytorch-simple                  # ê³ ì •ê°’ (PyTorch Runtime ì´ë¦„)

  trainer:
    # ============================================================
    # UI ì…ë ¥: ì´ë¯¸ì§€ ì£¼ì†Œ
    # ============================================================
    image: pytorch/pytorch:2.2.2-cuda11.8-cudnn8-runtime

    # ============================================================
    # UI ì…ë ¥: ë¶„ì‚°í•™ìŠµ ë…¸ë“œ ê°œìˆ˜
    # ============================================================
    numNodes: 2

    # ============================================================
    # UI ì…ë ¥: ì»¤ë§¨ë“œ
    # ============================================================
    command:
      - bash
      - -c
      - |
        # PyTorch í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ìë™ ì¶”ê°€)
        export RANK=${PET_NODE_RANK:-0}
        export LOCAL_RANK=${PET_LOCAL_RANK:-0}
        export WORLD_SIZE=${PET_NNODES:-1}
        export MASTER_ADDR=${PET_MASTER_ADDR:-localhost}
        export MASTER_PORT=${PET_MASTER_PORT:-29500}

        # ì‚¬ìš©ì ì…ë ¥ ì»¤ë§¨ë“œ (UIì—ì„œ ë°›ìŒ)
        python /workspace/scripts/train.py

    # ============================================================
    # UI ì…ë ¥: CPU, MEMORY, GPU
    # ============================================================
    resourcesPerNode:
      limits:
        cpu: "4"                           # UI ì…ë ¥: CPU ì œí•œ
        memory: "16Gi"                     # UI ì…ë ¥: MEMORY ì œí•œ
        nvidia.com/gpu: "1"                # UI ì…ë ¥: GPU ê°œìˆ˜
      requests:
        cpu: "2"                           # UI ì…ë ¥: CPU ìš”ì²­
        memory: "8Gi"                      # UI ì…ë ¥: MEMORY ìš”ì²­
        nvidia.com/gpu: "1"                # GPUëŠ” requests = limits

  # ============================================================
  # UI ì…ë ¥: ë³¼ë¥¨ ë§ˆìš´íŠ¸
  # ============================================================
  podTemplateOverrides:
    - targetJobs:
        - name: node
      spec:
        volumes:
          # ì†ŒìŠ¤ì½”ë“œ ë³¼ë¥¨
          - name: train-script
            configMap:
              name: user-train-script      # Backendê°€ ìƒì„±í•œ ConfigMap ì´ë¦„
              defaultMode: 0755

          # ë°ì´í„°ì…‹ ë³¼ë¥¨ (ì˜ˆì‹œ: PVC)
          - name: dataset
            persistentVolumeClaim:
              claimName: user-dataset-pvc

          # ëª¨ë¸ ì €ì¥ì†Œ ë³¼ë¥¨ (ì˜ˆì‹œ: PVC)
          - name: models
            persistentVolumeClaim:
              claimName: user-models-pvc

        containers:
          - name: node
            # ============================================================
            # UI ì…ë ¥: í™˜ê²½ë³€ìˆ˜
            # ============================================================
            env:
              - name: EPOCHS                # ì‚¬ìš©ì ì •ì˜ í™˜ê²½ë³€ìˆ˜
                value: "10"
              - name: BATCH_SIZE
                value: "64"
              - name: LEARNING_RATE
                value: "0.001"

            volumeMounts:
              - name: train-script
                mountPath: /workspace/scripts
                readOnly: true
              - name: dataset
                mountPath: /data
                readOnly: true
              - name: models
                mountPath: /models
                readOnly: false
```

---

#### **TensorFlow TrainJob ì˜ˆì‹œ**

```yaml
apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainJob
metadata:
  name: user-job-12345
  namespace: user-namespace
spec:
  runtimeRef:
    name: tensorflow-distributed           # ê³ ì •ê°’ (TensorFlow Runtime ì´ë¦„)

  trainer:
    # UI ì…ë ¥: ì´ë¯¸ì§€ ì£¼ì†Œ
    image: tensorflow/tensorflow:2.15.0-gpu

    # UI ì…ë ¥: ë¶„ì‚°í•™ìŠµ ë…¸ë“œ ê°œìˆ˜
    numNodes: 2

    # UI ì…ë ¥: ì»¤ë§¨ë“œ
    command:
      - bash
      - -c
      - |
        # TF_CONFIG ë¡œë“œ (ìë™ ì¶”ê°€)
        source /shared-env/tf_config.env
        echo "TF_CONFIG: $TF_CONFIG"

        # ì‚¬ìš©ì ì…ë ¥ ì»¤ë§¨ë“œ
        python3 /workspace/scripts/train.py

    # UI ì…ë ¥: CPU, MEMORY, GPU
    resourcesPerNode:
      limits:
        cpu: "4"
        memory: "16Gi"
        nvidia.com/gpu: "1"
      requests:
        cpu: "2"
        memory: "8Gi"
        nvidia.com/gpu: "1"

  # UI ì…ë ¥: ë³¼ë¥¨ ë§ˆìš´íŠ¸
  podTemplateOverrides:
    - targetJobs:
        - name: node
      spec:
        volumes:
          - name: train-script
            configMap:
              name: user-train-script
              defaultMode: 0755
          - name: dataset
            persistentVolumeClaim:
              claimName: user-dataset-pvc
          - name: models
            persistentVolumeClaim:
              claimName: user-models-pvc

        # âš ï¸ TensorFlow ì „ìš©: initContainerì— PET_NNODES ì„¤ì • í•„ìš”
        initContainers:
          - name: tf-config-generator
            env:
              - name: PET_NNODES
                value: "2"                 # numNodesì™€ ë™ì¼í•˜ê²Œ ì„¤ì •

        containers:
          - name: node
            # UI ì…ë ¥: í™˜ê²½ë³€ìˆ˜
            env:
              - name: EPOCHS
                value: "10"
              - name: BATCH_SIZE
                value: "64"

            volumeMounts:
              - name: train-script
                mountPath: /workspace/scripts
                readOnly: true
              - name: dataset
                mountPath: /data
                readOnly: true
              - name: models
                mountPath: /models
                readOnly: false
```

---

## Backend êµ¬í˜„ ê°€ì´ë“œ

### ğŸ”§ ì „ì²´ ì²˜ë¦¬ íë¦„

```
UI ìš”ì²­
  â†“
Backend API
  â†“
1. User ConfigMap ìƒì„± (ì‚¬ìš©ì ì†ŒìŠ¤ì½”ë“œ)
2. TrainJob YAML ìƒì„± (ìœ„ í…œí”Œë¦¿ + UI ì…ë ¥ê°’)
3. TrainJob ë°°í¬
  â†“
Kubernetes
  â†“
Pod ìƒì„± ë° í•™ìŠµ ì‹¤í–‰
```

---

### ğŸ“ êµ¬í˜„ ì˜ˆì‹œ (Python)

#### **1ë‹¨ê³„: User ConfigMap ìƒì„±**

```python
def create_user_configmap(user_id: str, namespace: str, training_code: str) -> str:
    """
    ì‚¬ìš©ì í•™ìŠµ ì½”ë“œë¥¼ ConfigMapìœ¼ë¡œ ìƒì„±

    Returns:
        ConfigMap ì´ë¦„
    """
    configmap_name = f"{user_id}-train-script"

    configmap = {
        "apiVersion": "v1",
        "kind": "ConfigMap",
        "metadata": {
            "name": configmap_name,
            "namespace": namespace
        },
        "data": {
            "train.py": training_code  # UIì—ì„œ ë°›ì€ Python ì½”ë“œ
        }
    }

    # Kubernetes APIë¡œ ìƒì„±
    k8s_core_v1.create_namespaced_config_map(
        namespace=namespace,
        body=configmap
    )

    return configmap_name
```

---

#### **2ë‹¨ê³„: TrainJob ìƒì„± í•¨ìˆ˜**

```python
def create_trainjob(
    user_id: str,
    namespace: str,
    framework: str,  # "pytorch" ë˜ëŠ” "tensorflow"
    image: str,
    num_nodes: int,
    cpu_request: str,
    cpu_limit: str,
    memory_request: str,
    memory_limit: str,
    gpu_count: int,
    command: str,
    env_vars: List[Dict[str, str]],
    volumes: List[Dict[str, Any]],
    configmap_name: str
) -> str:
    """
    TrainJob YAML ìƒì„± ë° ë°°í¬

    Args:
        user_id: ì‚¬ìš©ì ID
        namespace: ì‚¬ìš©ì ë„¤ì„ìŠ¤í˜ì´ìŠ¤
        framework: "pytorch" ë˜ëŠ” "tensorflow"
        image: Docker ì´ë¯¸ì§€ ì£¼ì†Œ
        num_nodes: ë¶„ì‚°í•™ìŠµ ë…¸ë“œ ê°œìˆ˜
        cpu_request/cpu_limit: CPU ë¦¬ì†ŒìŠ¤
        memory_request/memory_limit: ë©”ëª¨ë¦¬ ë¦¬ì†ŒìŠ¤
        gpu_count: GPU ê°œìˆ˜
        command: ì‚¬ìš©ì ì‹¤í–‰ ëª…ë ¹
        env_vars: [{"name": "KEY", "value": "VALUE"}, ...]
        volumes: [{"name": "vol1", "pvc": "pvc-name", "mountPath": "/data"}, ...]
        configmap_name: í•™ìŠµ ì½”ë“œ ConfigMap ì´ë¦„

    Returns:
        TrainJob ì´ë¦„
    """
    import time
    trainjob_name = f"{user_id}-job-{int(time.time())}"

    # Runtime ì´ë¦„ ê²°ì •
    runtime_name = "pytorch-simple" if framework == "pytorch" else "tensorflow-distributed"

    # í”„ë ˆì„ì›Œí¬ë³„ í™˜ê²½ë³€ìˆ˜ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    if framework == "pytorch":
        env_setup = """
        export RANK=${PET_NODE_RANK:-0}
        export LOCAL_RANK=${PET_LOCAL_RANK:-0}
        export WORLD_SIZE=${PET_NNODES:-1}
        export MASTER_ADDR=${PET_MASTER_ADDR:-localhost}
        export MASTER_PORT=${PET_MASTER_PORT:-29500}
        """
    else:  # tensorflow
        env_setup = """
        source /shared-env/tf_config.env
        echo "TF_CONFIG: $TF_CONFIG"
        """

    # ì „ì²´ ì»¤ë§¨ë“œ ì¡°í•©
    full_command = f"""
{env_setup}

# ì‚¬ìš©ì ì»¤ë§¨ë“œ
{command}
"""

    # ë³¼ë¥¨ ë° ë³¼ë¥¨ ë§ˆìš´íŠ¸ ìƒì„±
    volume_specs = []
    volume_mounts = []

    # ì†ŒìŠ¤ì½”ë“œ ë³¼ë¥¨ (í•„ìˆ˜)
    volume_specs.append({
        "name": "train-script",
        "configMap": {
            "name": configmap_name,
            "defaultMode": 0o755
        }
    })
    volume_mounts.append({
        "name": "train-script",
        "mountPath": "/workspace/scripts",
        "readOnly": True
    })

    # ì‚¬ìš©ì ì •ì˜ ë³¼ë¥¨ ì¶”ê°€
    for vol in volumes:
        volume_specs.append({
            "name": vol["name"],
            "persistentVolumeClaim": {
                "claimName": vol["pvc"]
            }
        })
        volume_mounts.append({
            "name": vol["name"],
            "mountPath": vol["mountPath"],
            "readOnly": vol.get("readOnly", False)
        })

    # TrainJob ìƒì„±
    trainjob = {
        "apiVersion": "trainer.kubeflow.org/v1alpha1",
        "kind": "TrainJob",
        "metadata": {
            "name": trainjob_name,
            "namespace": namespace
        },
        "spec": {
            "runtimeRef": {
                "name": runtime_name
            },
            "trainer": {
                "image": image,
                "numNodes": num_nodes,
                "command": ["bash", "-c", full_command],
                "resourcesPerNode": {
                    "limits": {
                        "cpu": cpu_limit,
                        "memory": memory_limit,
                        "nvidia.com/gpu": str(gpu_count)
                    },
                    "requests": {
                        "cpu": cpu_request,
                        "memory": memory_request,
                        "nvidia.com/gpu": str(gpu_count)
                    }
                }
            },
            "podTemplateOverrides": [
                {
                    "targetJobs": [{"name": "node"}],
                    "spec": {
                        "volumes": volume_specs,
                        "containers": [
                            {
                                "name": "node",
                                "env": env_vars,
                                "volumeMounts": volume_mounts
                            }
                        ]
                    }
                }
            ]
        }
    }

    # âš ï¸ TensorFlow ì „ìš©: initContainerì— PET_NNODES ì„¤ì •
    if framework == "tensorflow":
        trainjob["spec"]["podTemplateOverrides"][0]["spec"]["initContainers"] = [
            {
                "name": "tf-config-generator",
                "env": [
                    {
                        "name": "PET_NNODES",
                        "value": str(num_nodes)
                    }
                ]
            }
        ]

    # Kubernetes APIë¡œ ë°°í¬
    k8s_custom.create_namespaced_custom_object(
        group="trainer.kubeflow.org",
        version="v1alpha1",
        namespace=namespace,
        plural="trainjobs",
        body=trainjob
    )

    return trainjob_name
```

---

#### **3ë‹¨ê³„: API ì—”ë“œí¬ì¸íŠ¸ ì˜ˆì‹œ**

```python
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Any

router = APIRouter()

class VolumeMount(BaseModel):
    name: str
    pvc: str
    mountPath: str
    readOnly: bool = False

class TrainJobRequest(BaseModel):
    user_id: str
    namespace: str
    framework: str  # "pytorch" or "tensorflow"
    training_code: str
    image: str
    num_nodes: int
    cpu_request: str
    cpu_limit: str
    memory_request: str
    memory_limit: str
    gpu_count: int
    command: str
    env_vars: List[Dict[str, str]] = []
    volumes: List[VolumeMount] = []

@router.post("/trainjob/create")
async def create_training_job(request: TrainJobRequest):
    """
    í•™ìŠµ ì‘ì—… ìƒì„± API
    """
    try:
        # 1. User ConfigMap ìƒì„±
        configmap_name = create_user_configmap(
            user_id=request.user_id,
            namespace=request.namespace,
            training_code=request.training_code
        )

        # 2. TrainJob ìƒì„±
        trainjob_name = create_trainjob(
            user_id=request.user_id,
            namespace=request.namespace,
            framework=request.framework,
            image=request.image,
            num_nodes=request.num_nodes,
            cpu_request=request.cpu_request,
            cpu_limit=request.cpu_limit,
            memory_request=request.memory_request,
            memory_limit=request.memory_limit,
            gpu_count=request.gpu_count,
            command=request.command,
            env_vars=request.env_vars,
            volumes=[vol.dict() for vol in request.volumes],
            configmap_name=configmap_name
        )

        return {
            "status": "success",
            "trainjob_name": trainjob_name,
            "namespace": request.namespace
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

---

#### **4ë‹¨ê³„: API ìš”ì²­ ì˜ˆì‹œ**

```bash
curl -X POST http://localhost:8000/api/trainjob/create \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "user123",
    "namespace": "user-123",
    "framework": "pytorch",
    "training_code": "import torch\nimport torch.nn as nn\nprint(\"Training...\")",
    "image": "pytorch/pytorch:2.2.2-cuda11.8-cudnn8-runtime",
    "num_nodes": 2,
    "cpu_request": "2",
    "cpu_limit": "4",
    "memory_request": "8Gi",
    "memory_limit": "16Gi",
    "gpu_count": 1,
    "command": "python /workspace/scripts/train.py",
    "env_vars": [
      {"name": "EPOCHS", "value": "10"},
      {"name": "BATCH_SIZE", "value": "64"}
    ],
    "volumes": [
      {
        "name": "dataset",
        "pvc": "user123-dataset-pvc",
        "mountPath": "/data",
        "readOnly": true
      },
      {
        "name": "models",
        "pvc": "user123-models-pvc",
        "mountPath": "/models",
        "readOnly": false
      }
    ]
  }'
```

---

## í”„ë ˆì„ì›Œí¬ë³„ ì°¨ì´ì 

### PyTorch

**í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ìë™ ì¶”ê°€)**:
```bash
export RANK=${PET_NODE_RANK:-0}
export LOCAL_RANK=${PET_LOCAL_RANK:-0}
export WORLD_SIZE=${PET_NNODES:-1}
export MASTER_ADDR=${PET_MASTER_ADDR:-localhost}
export MASTER_PORT=${PET_MASTER_PORT:-29500}
```

**Runtime ì´ë¦„**: `pytorch-simple`

---

### TensorFlow

**í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ìë™ ì¶”ê°€)**:
```bash
source /shared-env/tf_config.env
echo "TF_CONFIG: $TF_CONFIG"
```

**Runtime ì´ë¦„**: `tensorflow-distributed`

**âš ï¸ ì¶”ê°€ í•„ìš” ì‚¬í•­**:
- `initContainers`ì— `PET_NNODES` í™˜ê²½ë³€ìˆ˜ ì„¤ì • í•„ìˆ˜
- `PET_NNODES` ê°’ì€ `trainer.numNodes`ì™€ ë™ì¼í•˜ê²Œ ì„¤ì •

```yaml
initContainers:
  - name: tf-config-generator
    env:
      - name: PET_NNODES
        value: "2"  # numNodesì™€ ë™ì¼
```

---

## ë°°í¬ ë° í…ŒìŠ¤íŠ¸

### 1. Runtime ì„¤ì¹˜ (ê´€ë¦¬ì - 1íšŒë§Œ)

```bash
# PyTorch Runtime
kubectl apply -f pytorch/pytorch-runtime-simple.yaml

# TensorFlow Runtime
kubectl apply -f tensorflow/tensorflow-runtime.yaml

# í™•ì¸
kubectl get clustertrainingruntimes
```

---

### 2. í…ŒìŠ¤íŠ¸ìš© ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±

```bash
kubectl create namespace test-user
```

---

### 3. PyTorch í…ŒìŠ¤íŠ¸

```bash
# User ConfigMap ìƒì„± (ì˜ˆì‹œ)
kubectl apply -f pytorch/pytorch-train-script-configmap.yaml -n test-user

# TrainJob ìƒì„±
kubectl apply -f pytorch/pytorch-distributed-with-configmap.yaml -n test-user

# ìƒíƒœ í™•ì¸
kubectl get trainjob -n test-user
kubectl get pods -n test-user | grep pytorch

# ë¡œê·¸ í™•ì¸
kubectl logs <pod-name> -n test-user
```

**ì„±ê³µ ë¡œê·¸**:
```
ğŸ‰ ë¶„ì‚° í•™ìŠµ ì´ˆê¸°í™” ì„±ê³µ!
  - Rank: 0/2
  - World Size: 2
  - Device: cuda:0
ğŸš€ ë¶„ì‚° í•™ìŠµ ì‹œì‘ (ì´ 2ê°œ ë…¸ë“œ)
Epoch 1, Batch 0/469, Loss: 2.3085
...
ğŸ‰ PyTorch ë¶„ì‚° í•™ìŠµ ì™„ë£Œ!
ì´ ë…¸ë“œ ìˆ˜: 2
ìµœì¢… í‰ê·  Loss: 0.0367
```

---

### 4. TensorFlow í…ŒìŠ¤íŠ¸

```bash
# User ConfigMap ìƒì„± (ì˜ˆì‹œ)
kubectl apply -f tensorflow/tensorflow-train-script-configmap.yaml -n test-user

# TrainJob ìƒì„±
kubectl apply -f tensorflow/tensorflow-distributed-with-configmap.yaml -n test-user

# ìƒíƒœ í™•ì¸
kubectl get trainjob -n test-user
kubectl get pods -n test-user | grep tensorflow

# ë¡œê·¸ í™•ì¸
kubectl logs <pod-name> -n test-user -c node
```

**ì„±ê³µ ë¡œê·¸**:
```
âœ… TF_CONFIG ë¡œë“œ ì™„ë£Œ: Worker 0
âœ… Worker 0 initialized with 2 replicas
ğŸš€ ë¶„ì‚° í•™ìŠµ ì‹œì‘ (ì´ 2ê°œ ì›Œì»¤)
Epoch 1/3...
ğŸ‰ TensorFlow ë¶„ì‚° í•™ìŠµ ì™„ë£Œ!
ì´ ë…¸ë“œ ìˆ˜: 2
ìµœì¢… Accuracy: 0.9884
```

---

## ì¤‘ìš” ì°¸ê³ ì‚¬í•­

### 1. RBAC ê¶Œí•œ

Backend Service Accountì— ë‹¤ìŒ ê¶Œí•œ í•„ìš”:

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: trainjob-backend-role
rules:
  - apiGroups: [""]
    resources: ["configmaps", "pods", "pods/log"]
    verbs: ["create", "get", "list", "update", "patch", "delete"]
  - apiGroups: ["trainer.kubeflow.org"]
    resources: ["trainjobs"]
    verbs: ["create", "get", "list", "update", "patch", "delete", "watch"]
```

---

### 2. GPU ë¦¬ì†ŒìŠ¤ ì„¤ì •

**GPU ì‚¬ìš©**:
```yaml
resourcesPerNode:
  limits:
    nvidia.com/gpu: "1"
  requests:
    nvidia.com/gpu: "1"  # GPUëŠ” requests = limits ë™ì¼í•˜ê²Œ
```

**GPU ì—†ì´ CPUë§Œ**:
```yaml
resourcesPerNode:
  limits:
    cpu: "4"
    memory: "16Gi"
  requests:
    cpu: "2"
    memory: "8Gi"
  # nvidia.com/gpu í•„ë“œ ì œê±°
```

---

### 3. ë³¼ë¥¨ ë§ˆìš´íŠ¸ íƒ€ì…

**ConfigMap**:
```yaml
- name: train-script
  configMap:
    name: user-train-script
    defaultMode: 0755
```

**PVC (PersistentVolumeClaim)**:
```yaml
- name: dataset
  persistentVolumeClaim:
    claimName: user-dataset-pvc
```

**hostPath (í…ŒìŠ¤íŠ¸ìš©ë§Œ)**:
```yaml
- name: local-data
  hostPath:
    path: /data
    type: Directory
```

---

### 4. ë¦¬ì†ŒìŠ¤ ì •ë¦¬

**TrainJob ì‚­ì œ**:
```bash
kubectl delete trainjob <trainjob-name> -n <namespace>
```
â†’ Pod ìë™ ì‚­ì œë¨

**ConfigMap ì‚­ì œ**:
```bash
kubectl delete configmap <configmap-name> -n <namespace>
```

---

## ë¬¸ì˜

êµ¬í˜„ ì¤‘ ë¬¸ì œê°€ ë°œìƒí•˜ê±°ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ ML íŒ€ì— ë¬¸ì˜í•˜ì„¸ìš”.

**í…ŒìŠ¤íŠ¸ ì™„ë£Œ**:
- âœ… PyTorch ë¶„ì‚° í•™ìŠµ (2 ë…¸ë“œ, GPU)
- âœ… TensorFlow ë¶„ì‚° í•™ìŠµ (2 ë…¸ë“œ, GPU)
- âœ… ë©€í‹° ë³¼ë¥¨ ë§ˆìš´íŠ¸ (ì†ŒìŠ¤ì½”ë“œ, ë°ì´í„°ì…‹, ëª¨ë¸)
- âœ… ì‚¬ìš©ì ì •ì˜ í™˜ê²½ë³€ìˆ˜
